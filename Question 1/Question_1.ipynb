{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ],
      "metadata": {
        "id": "TzYXIqDZVbZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries and training data"
      ],
      "metadata": {
        "id": "WXUUpGTdVc4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install wandb\n",
        "!pip install GPUtil\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import gc\n",
        "import random\n",
        "import math\n",
        "import wandb\n",
        "from GPUtil import showUtilization as gpu_usage\n",
        "from numba import cuda\n",
        "\n",
        "wandb.login(key='4734e60951ce310dbe17484eeeb5b3366b54850f')\n",
        "\n",
        "zip_file_path = '/content/aksharantar_sampled.zip'\n",
        "extracted_folder_path = '/content/'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder_path)\n",
        "\n",
        "extracted_folder_contents = os.listdir(extracted_folder_path)\n",
        "print(\"Contents of extracted folder:\", extracted_folder_contents)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(\"Trained on: \" + str(device))\n",
        "\n",
        "train_dataset = pd.read_csv('/content/aksharantar_sampled/hin/hin_train.csv', names=['English', 'Hindi'], header=None)\n",
        "test_dataset = pd.read_csv('/content/aksharantar_sampled/hin/hin_test.csv', names=['English', 'Hindi'], header=None)\n",
        "val_dataset = pd.read_csv('/content/aksharantar_sampled/hin/hin_valid.csv', names=['English', 'Hindi'], header=None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2cwEr_3RbeG",
        "outputId": "581a597e-0633-46bb-d852-7e23dfa28f9c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.1.1-py2.py3-none-any.whl (277 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.3/277.3 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.1.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.0\n",
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7394 sha256=1b270e39ba3e4983ee1fc71c9ef4148c8f5927e73fa59d6f57e0447350bc79ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of extracted folder: ['.config', 'aksharantar_sampled', 'aksharantar_sampled.zip', '__MACOSX', 'sample_data']\n",
            "Trained on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Support Functions:"
      ],
      "metadata": {
        "id": "nzNVt1UzU98-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_gpu_cache():\n",
        "    print(\"Initial GPU Usage\")\n",
        "    gpu_usage()\n",
        "    torch.cuda.empty_cache()\n",
        "    cuda.select_device(0)\n",
        "    cuda.close()\n",
        "    cuda.select_device(0)\n",
        "    print(\"GPU Usage after emptying the cache\")\n",
        "    gpu_usage()\n",
        "\n",
        "def split_into_tokens(word):\n",
        "    tokens = []\n",
        "    for x in word:\n",
        "        tokens.append(x)\n",
        "    return tokens\n",
        "\n",
        "def encode_english(word):\n",
        "    tokens = []\n",
        "    for x in word:\n",
        "        tokens.append(eng_dict[x])\n",
        "    for x in range(len(tokens), max_english_length):\n",
        "        tokens.append(eng_dict['<pad>'])\n",
        "    return tokens\n",
        "\n",
        "def encode_hindi(word):\n",
        "    tokens = []\n",
        "    for x in word:\n",
        "        tokens.append(hin_dict[x])\n",
        "    tokens.append(hin_dict['<eow>'])\n",
        "    for x in range(len(tokens), max_hindi_length + 1):\n",
        "        tokens.append(hin_dict['<pad>'])\n",
        "    return tokens\n",
        "\n",
        "def encode_test_english(word):\n",
        "    tokens = []\n",
        "    for x in word:\n",
        "        tokens.append(eng_dict[x])\n",
        "    for x in range(len(tokens), test_max_english_length):\n",
        "        tokens.append(eng_dict['<pad>'])\n",
        "    return tokens\n",
        "\n",
        "def encode_test_hindi(word):\n",
        "    tokens = []\n",
        "    for x in word:\n",
        "        tokens.append(hin_dict[x])\n",
        "    tokens.append(hin_dict['<eow>'])\n",
        "    for x in range(len(tokens), test_max_hindi_length):\n",
        "        tokens.append(hin_dict['<pad>'])\n",
        "    return tokens\n",
        "\n",
        "def encode_val_english(word):\n",
        "    tokens = []\n",
        "    for x in word:\n",
        "        tokens.append(eng_dict[x])\n",
        "    for x in range(len(tokens), val_max_english_length):\n",
        "        tokens.append(eng_dict['<pad>'])\n",
        "    return tokens\n",
        "\n",
        "def encode_val_hindi(word):\n",
        "    tokens = []\n",
        "    for x in word:\n",
        "        tokens.append(hin_dict[x])\n",
        "    tokens.append(hin_dict['<eow>'])\n",
        "    for x in range(len(tokens), val_max_hindi_length):\n",
        "        tokens.append(hin_dict['<pad>'])\n",
        "    return tokens\n",
        "\n",
        "def get_word(characters):\n",
        "    return \"\".join(characters)\n",
        "\n",
        "def calculate_accuracy(target, predictions, flag):\n",
        "    total = 0\n",
        "    for x in range(len(target)):\n",
        "        if torch.equal(target[x], predictions[x]):\n",
        "            total += 1\n",
        "    return total\n",
        "\n",
        "def translate_predictions(target, predictions, df):\n",
        "    i = len(df)\n",
        "    for x in range(len(predictions)):\n",
        "        original = []\n",
        "        for y in target[x]:\n",
        "            if y != 1:\n",
        "                original.append(y)\n",
        "            else:\n",
        "                break\n",
        "        predicted = []\n",
        "        for y in predictions[x]:\n",
        "            if y != 1:\n",
        "                predicted.append(y)\n",
        "            else:\n",
        "                break\n",
        "        df.loc[i, ['Original']] = get_word([reverse_hin[x.item()] for x in original])\n",
        "        df.loc[i, ['Predicted']] = get_word([reverse_hin[x.item()] for x in predicted])\n",
        "        i += 1\n",
        "    return df"
      ],
      "metadata": {
        "id": "DwTnrpttU5iz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing Variables:"
      ],
      "metadata": {
        "id": "wzQ22XpxVCYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_into_tokens(train_dataset.iloc[0]['Hindi'])\n",
        "\n",
        "max_english_length = 0\n",
        "max_hindi_length = 0\n",
        "test_max_english_length = 0\n",
        "test_max_hindi_length = 0\n",
        "\n",
        "for x in range(len(test_dataset)):\n",
        "    temp = 0\n",
        "    for y in test_dataset.iloc[x]['English']:\n",
        "        temp += 1\n",
        "    test_max_english_length = max(test_max_english_length, temp)\n",
        "\n",
        "for x in range(len(test_dataset)):\n",
        "    temp = 0\n",
        "    for y in test_dataset.iloc[x]['Hindi']:\n",
        "        temp += 1\n",
        "    test_max_hindi_length = max(test_max_hindi_length, temp)\n",
        "\n",
        "val_max_english_length = 0\n",
        "val_max_hindi_length = 0\n",
        "\n",
        "for x in range(len(val_dataset)):\n",
        "    temp = 0\n",
        "    for y in val_dataset.iloc[x]['English']:\n",
        "        temp += 1\n",
        "    val_max_english_length = max(val_max_english_length, temp)\n",
        "\n",
        "for x in range(len(val_dataset)):\n",
        "    temp = 0\n",
        "    for y in val_dataset.iloc[x]['Hindi']:\n",
        "        temp += 1\n",
        "    val_max_hindi_length = max(val_max_hindi_length, temp)\n",
        "\n",
        "english_vocab = []\n",
        "for x in range(len(train_dataset)):\n",
        "    temp = 0\n",
        "    for y in train_dataset.iloc[x]['English']:\n",
        "        temp += 1\n",
        "        if y not in english_vocab:\n",
        "            english_vocab.append(y)\n",
        "    if temp > max_english_length:\n",
        "        max_english_length = max(max_english_length, temp)\n",
        "\n",
        "hindi_vocab = []\n",
        "for x in range(len(train_dataset)):\n",
        "    temp = 0\n",
        "    for y in train_dataset.iloc[x]['Hindi']:\n",
        "        temp += 1\n",
        "        if y not in hindi_vocab:\n",
        "            hindi_vocab.append(y)\n",
        "    max_hindi_length = max(temp, max_hindi_length)\n",
        "for x in range(len(test_dataset)):\n",
        "    for y in test_dataset.iloc[x]['Hindi']:\n",
        "        if y not in hindi_vocab:\n",
        "            hindi_vocab.append(y)\n",
        "\n",
        "english_vocab = sorted(english_vocab)\n",
        "hindi_vocab = sorted(hindi_vocab)\n",
        "\n",
        "eng_dict = {}\n",
        "reverse_eng = {}\n",
        "\n",
        "for x in range(len(english_vocab)):\n",
        "    eng_dict[english_vocab[x]] = x + 3\n",
        "    reverse_eng[x + 3] = english_vocab[x]\n",
        "eng_dict['<sow>'] = 0\n",
        "eng_dict['<eow>'] = 1\n",
        "eng_dict['<pad>'] = 2\n",
        "reverse_eng[0] = '<sow>'\n",
        "reverse_eng[1] = '<eow>'\n",
        "reverse_eng[2] = '<pad>'\n",
        "\n",
        "hin_dict = {}\n",
        "reverse_hin = {}\n",
        "for x in range(len(hindi_vocab)):\n",
        "    hin_dict[hindi_vocab[x]] = x + 3\n",
        "    reverse_hin[x + 3] = hindi_vocab[x]\n",
        "hin_dict['<sow>'] = 0\n",
        "hin_dict['<eow>'] = 1\n",
        "hin_dict['<pad>'] = 2\n",
        "reverse_hin[0] = '<sow>'\n",
        "reverse_hin[1] = '<eow>'\n",
        "reverse_hin[2] = '<pad>'\n",
        "\n",
        "encode_english(train_dataset.iloc[0]['English'])\n",
        "\n",
        "eng_words = []\n",
        "hin_words = []\n",
        "for x in range(len(train_dataset)):\n",
        "    eng_words.append(encode_english(train_dataset.iloc[x]['English']))\n",
        "    hin_words.append(encode_hindi(train_dataset.iloc[x]['Hindi']))\n",
        "eng_words = torch.tensor(eng_words)\n",
        "hin_words = torch.tensor(hin_words)\n",
        "max_hindi_length\n",
        "\n",
        "max_hindi_length += 1\n",
        "test_max_hindi_length += 1\n",
        "val_max_hindi_length += 1\n",
        "max_hindi_length\n",
        "\n",
        "val_eng_words = []\n",
        "val_hin_words = []\n",
        "for x in range(len(val_dataset)):\n",
        "    val_eng_words.append(encode_val_english(val_dataset.iloc[x]['English']))\n",
        "    val_hin_words.append(encode_val_hindi(val_dataset.iloc[x]['Hindi']))\n",
        "val_eng_words = torch.tensor(val_eng_words)\n",
        "val_hin_words = torch.tensor(val_hin_words)\n",
        "\n",
        "test_eng_words = []\n",
        "test_hin_words = []\n",
        "for x in range(len(test_dataset)):\n",
        "    test_eng_words.append(encode_test_english(test_dataset.iloc[x]['English']))\n",
        "    test_hin_words.append(encode_test_hindi(test_dataset.iloc[x]['Hindi']))\n",
        "test_eng_words = torch.tensor(test_eng_words)\n",
        "test_hin_words = torch.tensor(test_hin_words)"
      ],
      "metadata": {
        "id": "4460ZFpCVA7V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder Decoder:"
      ],
      "metadata": {
        "id": "2liwi_6qVHHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, char_embed_size, hidden_size, no_of_layers, dropout, rnn):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layer = no_of_layers\n",
        "        self.rnn = rnn\n",
        "        self.embedding = nn.Embedding(len(eng_dict), char_embed_size).to(device)\n",
        "        self.embedding.weight.requires_grad = True\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.LSTM = nn.LSTM(char_embed_size, hidden_size, self.layer, batch_first=True, bidirectional=True).to(device)\n",
        "        self.RNN = nn.RNN(char_embed_size, hidden_size, self.layer, batch_first=True, bidirectional=True).to(device)\n",
        "        self.GRU = nn.GRU(char_embed_size, hidden_size, self.layer, batch_first=True, bidirectional=True).to(device)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        embedded = self.embedding(input)\n",
        "        embedded1 = self.drop(embedded)\n",
        "        cell1 = cell\n",
        "        if self.rnn == 'RNN':\n",
        "            output, hidden1 = self.RNN(embedded1, hidden)\n",
        "        elif self.rnn == 'LSTM':\n",
        "            output, (hidden1, cell1) = self.LSTM(embedded1, (hidden, cell))\n",
        "        elif self.rnn == 'GRU':\n",
        "            output, hidden1 = self.GRU(embedded1, hidden)\n",
        "        return output, (hidden1, cell1)\n",
        "\n",
        "\n",
        "class DecoderNoAttention(nn.Module):\n",
        "    def __init__(self, char_embed_size, hidden_size, no_of_layers, dropout, batchsize, rnn):\n",
        "        super(DecoderNoAttention, self).__init__()\n",
        "        self.layer = no_of_layers\n",
        "        self.batchsize = batchsize\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = rnn\n",
        "        self.embedding = nn.Embedding(len(hin_dict), char_embed_size).to(device)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.embedding.weight.requires_grad = True\n",
        "        self.LSTM = nn.LSTM(char_embed_size + hidden_size * 2, hidden_size, self.layer, batch_first=True).to(device)\n",
        "        self.RNN = nn.RNN(char_embed_size + hidden_size * 2, hidden_size, self.layer, batch_first=True).to(device)\n",
        "        self.GRU = nn.GRU(char_embed_size + hidden_size * 2, hidden_size, self.layer, batch_first=True).to(device)\n",
        "        self.linear = nn.Linear(hidden_size, len(hin_dict), bias=True).to(device)\n",
        "        self.softmax = nn.Softmax(dim=2).to(device)\n",
        "\n",
        "    def forward(self, input, hidden, cell, og_hidden, matrix):\n",
        "        embedded = self.embedding(input)\n",
        "        s1 = og_hidden.size()[1]\n",
        "        s2 = og_hidden.size()[2]\n",
        "        embedded1 = torch.cat((embedded, og_hidden[0].resize(s1, 1, s2), og_hidden[1].resize(s1, 1, s2)), dim=2)\n",
        "        embedded2 = self.drop(embedded1)\n",
        "        cell1 = cell\n",
        "        if self.rnn == 'LSTM':\n",
        "            output, (hidden1, cell1) = self.LSTM(embedded2, (hidden, cell))\n",
        "        elif self.rnn == 'RNN':\n",
        "            output, hidden1 = self.RNN(embedded2, hidden)\n",
        "        elif self.rnn == 'GRU':\n",
        "            output, hidden1 = self.GRU(embedded2, hidden)\n",
        "        output1 = self.linear(output)\n",
        "        return output1, (hidden1, cell1)\n",
        "\n",
        "def val_evaluate(attention, val_eng_words, val_hin_words, encoder, decoder, batch_size, hidden_size, char_embed_size, no_of_layers):\n",
        "    with torch.no_grad():\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        for x in range(0, len(val_dataset), batch_size):\n",
        "            loss = 0\n",
        "            input_tensor = val_eng_words[x:x + batch_size].to(device)\n",
        "            if input_tensor.size()[0] < batch_size:\n",
        "                break\n",
        "            en_hidden = torch.zeros(2 * no_of_layers, batch_size, hidden_size).to(device)\n",
        "            en_cell = torch.zeros(2 * no_of_layers, batch_size, hidden_size).to(device)\n",
        "            output, (hidden, cell) = encoder.forward(input_tensor, en_hidden, en_cell)\n",
        "            del input_tensor\n",
        "            del en_hidden\n",
        "            del en_cell\n",
        "            output = torch.split(output, [hidden_size, hidden_size], dim=2)\n",
        "            output = torch.add(output[0], output[1]) / 2\n",
        "            input2 = []\n",
        "            for y in range(batch_size):\n",
        "                input2.append([0])\n",
        "            input2 = torch.tensor(input2).to(device)\n",
        "            hidden = hidden.resize(2, no_of_layers, batch_size, hidden_size)\n",
        "            hidden1 = torch.add(hidden[0], hidden[1]) / 2\n",
        "            cell = cell.resize(2, no_of_layers, batch_size, hidden_size)\n",
        "            cell1 = torch.add(cell[0], cell[1]) / 2\n",
        "            OGhidden = hidden1\n",
        "            predicted = []\n",
        "            predictions = []\n",
        "            if attention:\n",
        "                temp = output\n",
        "            else:\n",
        "                temp = OGhidden\n",
        "            for i in range(val_max_hindi_length):\n",
        "                output1, (hidden1, cell1) = decoder.forward(input2, hidden1, cell1, temp, False)\n",
        "                predicted.append(output1)\n",
        "                output2 = decoder.softmax(output1)\n",
        "                output3 = torch.argmax(output2, dim=2)\n",
        "                predictions.append(output3)\n",
        "                input2 = output3\n",
        "            predicted = torch.cat(tuple(x for x in predicted), dim=1).to(device).resize(val_max_hindi_length * batch_size, len(hin_dict))\n",
        "            predictions = torch.cat(tuple(x for x in predictions), dim=1).to(device)\n",
        "            total_acc += calculate_accuracy(val_hin_words[x:x + batch_size].to(device), predictions, x)\n",
        "            loss = nn.CrossEntropyLoss(reduction='sum')(predicted, val_hin_words[x:x + batch_size].reshape(-1).to(device))\n",
        "            with torch.no_grad():\n",
        "                total_loss += loss.item()\n",
        "        validation_loss = total_loss / (len(val_dataset) * val_max_hindi_length)\n",
        "        validation_accuracy = (total_acc / len(val_dataset)) * 100\n",
        "        del predictions\n",
        "        del predicted\n",
        "        del input2\n",
        "        del output1\n",
        "        del output2\n",
        "        del output3\n",
        "        del hidden1\n",
        "        del cell1\n",
        "        del OGhidden\n",
        "        del output\n",
        "        del cell\n",
        "        return validation_loss, validation_accuracy"
      ],
      "metadata": {
        "id": "lACHQtnRVFWL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training function:"
      ],
      "metadata": {
        "id": "VQmmvOQpVN2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(batch_size, hidden_size, char_embed_size, no_of_layers, dropout, epochs, rnn):\n",
        "    gc.collect()\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    encoder = Encoder(char_embed_size, hidden_size, no_of_layers, dropout, rnn).to(device)\n",
        "    decoder = DecoderNoAttention(char_embed_size, hidden_size, no_of_layers, dropout, batch_size, rnn).to(device)\n",
        "    # print(encoder.parameters)\n",
        "    # print(decoder.parameters)\n",
        "    opt_encoder = optim.Adam(encoder.parameters(), lr=0.001)\n",
        "    opt_decoder = optim.Adam(decoder.parameters(), lr=0.001)\n",
        "    teacher_ratio = 0.5\n",
        "    epoch_count = 0\n",
        "    for _ in range(epochs):\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        for x in range(0, len(train_dataset), batch_size):\n",
        "            loss = 0\n",
        "            opt_encoder.zero_grad()\n",
        "            opt_decoder.zero_grad()\n",
        "            input_tensor = eng_words[x:x + batch_size].to(device)\n",
        "            # taking initial hidden and cell states as (2* no_of_layers, hidden_size, hidden_size) because I have considered encoder to be bidirectional\n",
        "            en_hidden = torch.zeros(2 * no_of_layers, batch_size, hidden_size).to(device)\n",
        "            en_cell = torch.zeros(2 * no_of_layers, batch_size, hidden_size).to(device)\n",
        "            if input_tensor.size()[0] < batch_size:\n",
        "                break\n",
        "            output, (hidden, cell) = encoder.forward(input_tensor, en_hidden, en_cell)\n",
        "            del en_hidden\n",
        "            del en_cell\n",
        "            del input_tensor\n",
        "            input2 = []\n",
        "            for y in range(batch_size):\n",
        "                input2.append([0])\n",
        "            input2 = torch.tensor(input2).to(device)\n",
        "            hidden = hidden.resize(2, no_of_layers, batch_size, hidden_size)\n",
        "            cell = cell.resize(2, no_of_layers, batch_size, hidden_size)\n",
        "            # averaging due to bidirectional encoder\n",
        "            hidden1 = torch.add(hidden[0], hidden[1]) / 2\n",
        "            cell1 = torch.add(cell[0], cell[1]) / 2\n",
        "            OGhidden = hidden1\n",
        "            predicted = []\n",
        "            predictions = []\n",
        "            use_teacher_forcing = True if random.random() < teacher_ratio else False\n",
        "            if use_teacher_forcing:\n",
        "                for i in range(max_hindi_length):\n",
        "                    output1, (hidden1, cell1) = decoder.forward(input2, hidden1, cell1, OGhidden, False)\n",
        "                    predicted.append(output1)\n",
        "                    output2 = decoder.softmax(output1)\n",
        "                    output3 = torch.argmax(output2, dim=2)\n",
        "                    predictions.append(output3)\n",
        "                    input2 = hin_words[x:x + batch_size, i].to(device).resize(batch_size, 1)\n",
        "            else:\n",
        "                for i in range(max_hindi_length):\n",
        "                    output1, (hidden1, cell1) = decoder.forward(input2, hidden1, cell1, OGhidden, False)\n",
        "                    predicted.append(output1)\n",
        "                    output2 = decoder.softmax(output1)\n",
        "                    output3 = torch.argmax(output2, dim=2)\n",
        "                    predictions.append(output3)\n",
        "                    input2 = output3\n",
        "            predicted = torch.cat(tuple(x for x in predicted), dim=1).to(device).resize(max_hindi_length * batch_size, len(hin_dict))\n",
        "            predictions = torch.cat(tuple(x for x in predictions), dim=1).to(device)\n",
        "            total_acc += calculate_accuracy(hin_words[x:x + batch_size].to(device), predictions, x)\n",
        "            loss = nn.CrossEntropyLoss(reduction='sum')(predicted, hin_words[x:x + batch_size].reshape(-1).to(device))\n",
        "            with torch.no_grad():\n",
        "                total_loss += loss.item()\n",
        "            loss.backward(retain_graph=True)\n",
        "            torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1)\n",
        "            torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1)\n",
        "            opt_encoder.step()\n",
        "            opt_decoder.step()\n",
        "        del predictions\n",
        "        del predicted\n",
        "        del input2\n",
        "        del output1\n",
        "        del output2\n",
        "        del output3\n",
        "        del hidden1\n",
        "        del cell1\n",
        "        del OGhidden\n",
        "        del output\n",
        "        del cell\n",
        "        training_loss = total_loss / (51200 * max_hindi_length)\n",
        "        training_accuracy = total_acc / 512\n",
        "        validation_loss, validation_accuracy = val_evaluate(False, val_eng_words, val_hin_words, encoder, decoder, batch_size, hidden_size, char_embed_size, no_of_layers)\n",
        "        wandb.log({'training_accuracy': training_accuracy, 'validation_accuracy': validation_accuracy, 'training_loss': training_loss, 'validation_loss': validation_loss, 'epoch': epoch_count + 1})\n",
        "        print(\"Epoch: \" + str(epoch_count + 1) + \"/\" + str(epochs) + \"; Train loss: \" + str(training_loss) + \"; Val loss: \" + str(validation_loss))\n",
        "        epoch_count += 1\n",
        "    return encoder, decoder\n"
      ],
      "metadata": {
        "id": "kJr8pR0LVKID"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}